session_id,session_name,room,day,day_part,time,presenter_name,title,abstract,Bio
K1,Keynote: Jevin West,A,1,0,9:00,Jevin West,,,
K2,Keynote: Linda Steg,A,1,1,16:30,Linda Steg,,,
K3,Keynote: Sharad Goel,A,1,1,17:15,Sharad Goel,Everything but the Kitchen Sink,"When estimating the risk of an adverse outcome, common statistical guidance is to include all available factors to maximize predictive performance. But I’ll argue that this popular ""kitchen-sink"" approach can in fact worsen predictions when the target of prediction differs from the true outcome of interest (e.g., with criminal risk assessments, predicting future arrests as a proxy for future crime). And even when predictions do improve, the benefits are often not as large as generally believed. I'll connect these results to current debates in criminal justice and healthcare.","Sharad Goel is a Professor of Public Policy at Harvard Kennedy School. He looks at public policy through the lens of computer science, bringing a computational perspective to a diverse range of contemporary social and political issues, including criminal justice reform, democratic governance, and the equitable design of algorithms. Prior to joining Harvard, Sharad was on the faculty at Stanford University, with appointments in management science & engineering, computer science, sociology, and the law school. He holds an undergraduate degree in mathematics from the University of Chicago, as well as a master’s degree in computer science and a doctorate in applied mathematics from Cornell University."
K4,Keynote: Molly Crockett,A,2,0,9:00,Molly Crockett,,,
K5,Keynote: Lisa Anne Hendriks,A,2,1,16:30,Lisa Anne Hendriks,Measuring and Mitigating Harm in AI Generated Language,"Recent language models like ChatGPT and Bard are capable of generating engaging and interesting human-like text. However, as progress on these models progresses, researchers, policy makers, and the public have raised serious concerns about their ability to generate harmful language, including language that is toxic or socially biased. In this talk, I will discuss our work at DeepMind to anticipate ethical risks in language models, then discuss how we measure toxicity and bias in our models. In particular, I'll focus on challenges operationalizing anticipated risks into reliable metrics.","Lisa Anne Hendricks is a research scientist at DeepMind. Her research interests include the intersection of language and vision and building fair and ethical AI. A common theme in both Lisa Anne’s multimodal and fairness research is probing whether models understand human language or whether they rely on learned correlations, with an aim to both accurately measure and mitigate potential failure modes. At DeepMind, Lisa has led the fairness analysis on many of DeepMind's large models including Gopher, Chinchilla, and Sparrow. She graduated with her PhD from UC Berkeley in 2019, where she focused on image captioning and text-based video retrieval. She completed her undergraduate studies at Rice University in 2013."
K6,Keynote: Stefan Gössling,A,2,1,17:15,Stefan Gössling,"Transport, mobilities, and climate change: Is there an Avenger moment?
","Transport emissions continue to grow, with very limited evidence of future change: Demand seems to continuously grow, outpacing efficiency gains. This raises the question of the social drivers of transport demand, such as social media, travel influencers, digital nomadism, and the aspirational lifestyles of the carbon elites, as underfeeding personal identities, social norms, and social capital generation. Given the evidence that technology innovations appear to constantly increase demand for travel and transport, the question is raised whether the arrival of AI represents an Avenger moment. Can we trust technology to support the transport transition? 
",
K7,Keynote: Joanna Bryson,A,3,0,9:00,Joanna Bryson,Science and Power in the Context of AI Policy,"Suddenly those of us who work in and with AI have moved from the academic margins into a whirlwind of power, money, international security, and hype. Fortunately, computational social sciences can help us understand these new contexts, and likely consequences of technological (and climactic) transformations. In this talk I review primarily simulation results explaining that cooperation is natural, despotism is too (in some contexts), trust depends on absence of information, and polarisation on economic precarity. I then pivot to data science supporting the polarisation model, and then showing the power dynamics of at least some of the transnational AI regulatory games we are observing.","Joanna Bryson is expert in intelligence — both natural and artificial. With degrees in Social and Computer Sciences from Chicago, Edinburgh and MIT, her scientific research appears in venues from reddit to Science, and her policy voice is heard in the UN, EU, CoE, OSCE, OECD and GPAI. Since February 2020, Bryson has been Professor of Ethics and Technology at Hertie School of Governance, Berlin."
K8,Keynote: Tim Althoff,A,3,0,9:45,Tim Althoff,,,
K9,Keynote: Lauren Brent,A,3,1,16:30,Lauren Brent,,,
K10,Keynote: Esteban Moro,A,3,1,17:15,Esteban Moro,Understanding urban social resilience through behavioral mobility data,"The economic and social progress of our urban areas, institutions, and labor markets depend on the diversity and resilience of the social fabric in cities. However, several major forces can erode these connections, such as income or racial segregation and differences in education and job access. In this talk, I will present recent research on understanding the fragility of the network of social connections and interactions in cities by analyzing behavioral mobility data and its relationship with networked inequalities, such as experienced segregation, access to healthy food, and adaptation to the recent pandemic. I will also discuss potential data-driven interventions aimed at reinforcing the social fabric in cities and mitigating the detrimental impacts of networked inequalities.","Esteban Moro is a researcher and data scientist at MIT Connection Science and a professor at Universidad Carlos III (UC3M) in Spain. His work lies at the intersection of big data, network science, and computational social science, with a focus on human dynamics, collective intelligence, social networks, and urban mobility in areas such as viral marketing, natural disaster management, and economic segregation in cities. He has received numerous awards for his research, including the “Shared University Award” from IBM in 2007 for his research on modeling viral marketing in social networks and the “Excellence in Research” Awards in 2013 and 2015 from UC3M. Esteban's work has appeared in major journals such as Nature Communications, Nature Human Behavior, PNAS, and Science Advances and is regularly covered by media outlets such as The Atlantic, The Washington Post, The Wall Street Journal, and El País (Spain)."